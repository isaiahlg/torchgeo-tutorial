{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "35303546",
      "metadata": {
        "id": "35303546"
      },
      "source": [
        "Source: https://torchgeo.readthedocs.io/en/stable/tutorials/getting_started.html\n",
        "\n",
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9478ed9a",
      "metadata": {
        "id": "9478ed9a"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "In this tutorial, we demonstrate some of the basic features of TorchGeo and show how easy it is to use if you're already familiar with other PyTorch domain libraries like torchvision.\n",
        "\n",
        "It's recommended to run this notebook on Google Colab if you don't have your own GPU. Click the \"Open in Colab\" button above to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f10e9f",
      "metadata": {
        "id": "34f10e9f"
      },
      "source": [
        "## Local Environment Setup\n",
        "\n",
        "Assuming you already have a python environment for `pytorch` setup, you only need to install TorchGeo. It's best to use `pip` for this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019092f0",
      "metadata": {
        "id": "019092f0"
      },
      "outputs": [],
      "source": [
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393aecba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# for this tutorial, we need to manually downgrade rasterio to an earlier version to get around a bug\n",
        "%pip install \"rasterio<1.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db9f791",
      "metadata": {
        "id": "4db9f791"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Next, we import TorchGeo and any other libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3d92b0f1",
      "metadata": {
        "id": "3d92b0f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchgeo.datasets import NAIP, ChesapeakeDE, stack_samples\n",
        "from torchgeo.datasets.utils import download_url\n",
        "from torchgeo.samplers import RandomGeoSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f26e4b8",
      "metadata": {
        "id": "7f26e4b8"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "For this tutorial, we'll be using imagery from the [National Agriculture Imagery Program (NAIP)](https://catalog.data.gov/dataset/national-agriculture-imagery-program-naip) and labels from the [Chesapeake Bay High-Resolution Land Cover Project](https://www.chesapeakeconservancy.org/conservation-innovation-center/high-resolution-data/land-cover-data-project/). First, we manually download a few NAIP tiles and create a PyTorch Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4a39af46",
      "metadata": {
        "id": "4a39af46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: data\\naip\\m_3807511_ne_18_060_20181104.tif\n",
            "Using downloaded and verified file: data\\naip\\m_3807511_se_18_060_20181104.tif\n",
            "Using downloaded and verified file: data\\naip\\m_3807512_nw_18_060_20180815.tif\n",
            "Using downloaded and verified file: data\\naip\\m_3807512_sw_18_060_20180815.tif\n"
          ]
        }
      ],
      "source": [
        "# naip_root = os.path.join(tempfile.gettempdir(), 'naip')\n",
        "naip_root = os.path.join('data', 'naip')\n",
        "naip_url = (\n",
        "    'https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/'\n",
        ")\n",
        "tiles = [\n",
        "    'm_3807511_ne_18_060_20181104.tif',\n",
        "    'm_3807511_se_18_060_20181104.tif',\n",
        "    'm_3807512_nw_18_060_20180815.tif',\n",
        "    'm_3807512_sw_18_060_20180815.tif',\n",
        "]\n",
        "for tile in tiles:\n",
        "    download_url(naip_url + tile, naip_root)\n",
        "\n",
        "naip = NAIP(naip_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25bad40",
      "metadata": {
        "id": "e25bad40"
      },
      "source": [
        "Next, we tell TorchGeo to automatically download the corresponding Chesapeake labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "689bb2b0",
      "metadata": {
        "id": "689bb2b0"
      },
      "outputs": [],
      "source": [
        "# chesapeake_root = os.path.join(tempfile.gettempdir(), 'chesapeake')\n",
        "chesapeake_root = os.path.join('data', 'chesapeake')\n",
        "os.makedirs(chesapeake_root, exist_ok=True)\n",
        "chesapeake = ChesapeakeDE(chesapeake_root, crs=naip.crs, res=naip.res, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f2d78b",
      "metadata": {
        "id": "56f2d78b"
      },
      "source": [
        "Finally, we create an IntersectionDataset so that we can automatically sample from both GeoDatasets simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "daefbc4d",
      "metadata": {
        "id": "daefbc4d"
      },
      "outputs": [],
      "source": [
        "dataset = naip & chesapeake"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ded44652",
      "metadata": {
        "id": "ded44652"
      },
      "source": [
        "## Sampler\n",
        "\n",
        "Unlike typical PyTorch Datasets, TorchGeo GeoDatasets are indexed using lat/long/time bounding boxes. This requires us to use a custom GeoSampler instead of the default sampler/batch_sampler that comes with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b8a0d99c",
      "metadata": {
        "id": "b8a0d99c"
      },
      "outputs": [],
      "source": [
        "sampler = RandomGeoSampler(dataset, size=1000, length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8c1c52",
      "metadata": {
        "id": "5b8c1c52"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "Now that we have a Dataset and Sampler, we can combine these into a single DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "96faa142",
      "metadata": {
        "id": "96faa142"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, sampler=sampler, collate_fn=stack_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ae63f7",
      "metadata": {
        "id": "64ae63f7"
      },
      "source": [
        "## Training\n",
        "\n",
        "Other than that, the rest of the training pipeline is the same as it is for torchvision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8a2b44f8",
      "metadata": {
        "id": "8a2b44f8"
      },
      "outputs": [],
      "source": [
        "for sample in dataloader:\n",
        "    image = sample['image']\n",
        "    target = sample['mask']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "getting_started.ipynb",
      "provenance": []
    },
    "execution": {
      "timeout": 1200
    },
    "kernelspec": {
      "display_name": "pyt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
