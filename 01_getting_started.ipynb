{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "35303546",
      "metadata": {
        "id": "35303546"
      },
      "source": [
        "Source: https://torchgeo.readthedocs.io/en/stable/tutorials/getting_started.html\n",
        "\n",
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9478ed9a",
      "metadata": {
        "id": "9478ed9a"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "In this tutorial, we demonstrate some of the basic features of TorchGeo and show how easy it is to use if you're already familiar with other PyTorch domain libraries like torchvision.\n",
        "\n",
        "It's recommended to run this notebook on Google Colab if you don't have your own GPU. Click the \"Open in Colab\" button above to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f10e9f",
      "metadata": {
        "id": "34f10e9f"
      },
      "source": [
        "## Setup\n",
        "\n",
        "You need a Python environment to run this notebook. You can either do this in Google Colab, or by setting up a local python environment. I like to set my up using conda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536ccbf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a conda environment with python 3.11 for pytorch\n",
        "%conda create --name pyt python=3.11 \n",
        "%conda activate pyt\n",
        "\n",
        "# run this next line specific to your OS and GPU configuration. Use CPU if you don't have CUDA.\n",
        "# https://pytorch.org/get-started/locally/\n",
        "# this example is for a linux system with CUDA 12.1\n",
        "%conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d587b5",
      "metadata": {},
      "source": [
        "Now we can install TorchGeo. It's best to use `pip` for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019092f0",
      "metadata": {
        "id": "019092f0"
      },
      "outputs": [],
      "source": [
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db9f791",
      "metadata": {
        "id": "4db9f791"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Next, we import TorchGeo and any other libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3d92b0f1",
      "metadata": {
        "id": "3d92b0f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchgeo.datasets import NAIP, ChesapeakeDE, stack_samples\n",
        "from torchgeo.datasets.utils import download_url\n",
        "from torchgeo.samplers import RandomGeoSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f26e4b8",
      "metadata": {
        "id": "7f26e4b8"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "For this tutorial, we'll be using imagery from the [National Agriculture Imagery Program (NAIP)](https://catalog.data.gov/dataset/national-agriculture-imagery-program-naip) and labels from the [Chesapeake Bay High-Resolution Land Cover Project](https://www.chesapeakeconservancy.org/conservation-innovation-center/high-resolution-data/land-cover-data-project/). First, we manually download a few NAIP tiles and create a PyTorch Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4a39af46",
      "metadata": {
        "id": "4a39af46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/m_3807511_ne_18_060_20181104.tif to /tmp/naip/m_3807511_ne_18_060_20181104.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 513332284/513332284 [01:06<00:00, 7700744.96it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/m_3807511_se_18_060_20181104.tif to /tmp/naip/m_3807511_se_18_060_20181104.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 521985441/521985441 [01:36<00:00, 5404524.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/m_3807512_nw_18_060_20180815.tif to /tmp/naip/m_3807512_nw_18_060_20180815.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 489865657/489865657 [01:10<00:00, 6981898.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/m_3807512_sw_18_060_20180815.tif to /tmp/naip/m_3807512_sw_18_060_20180815.tif\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 484476647/484476647 [01:16<00:00, 6323757.24it/s] \n"
          ]
        }
      ],
      "source": [
        "naip_root = os.path.join(tempfile.gettempdir(), 'naip')\n",
        "naip_url = (\n",
        "    'https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/'\n",
        ")\n",
        "tiles = [\n",
        "    'm_3807511_ne_18_060_20181104.tif',\n",
        "    'm_3807511_se_18_060_20181104.tif',\n",
        "    'm_3807512_nw_18_060_20180815.tif',\n",
        "    'm_3807512_sw_18_060_20180815.tif',\n",
        "]\n",
        "for tile in tiles:\n",
        "    download_url(naip_url + tile, naip_root)\n",
        "\n",
        "naip = NAIP(naip_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25bad40",
      "metadata": {
        "id": "e25bad40"
      },
      "source": [
        "Next, we tell TorchGeo to automatically download the corresponding Chesapeake labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "689bb2b0",
      "metadata": {
        "id": "689bb2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://hf.co/datasets/torchgeo/chesapeake/resolve/1e0370eda6a24d93af4153745e54fd383d015bf5/de_lulc_2013_2022-Edition.zip\n",
            "Downloading https://cdn-lfs-us-1.hf.co/repos/b1/d9/b1d907e4abc2017ba5639b5383cb747c467032b813359bb2ceb94fe88674bac3/ced3e274bfd8531915cb21d1a3faad31c9de859648feb8b8daec245f343c0b5c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27de_lulc_2013_2022-Edition.zip%3B+filename%3D%22de_lulc_2013_2022-Edition.zip%22%3B&response-content-type=application%2Fzip&Expires=1727737210&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzczNzIxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2IxL2Q5L2IxZDkwN2U0YWJjMjAxN2JhNTYzOWI1MzgzY2I3NDdjNDY3MDMyYjgxMzM1OWJiMmNlYjk0ZmU4ODY3NGJhYzMvY2VkM2UyNzRiZmQ4NTMxOTE1Y2IyMWQxYTNmYWFkMzFjOWRlODU5NjQ4ZmViOGI4ZGFlYzI0NWYzNDNjMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=qdsppKbpJ462RPRBujj-UISFwwuXD6M1GiNMxFvwOOQKm0v%7EQpA%7ESYtWUNJL%7EV0Svpi1PZL6E0cUgX-ifpYjUJKb2OADMSwCCTJAlgzMWnyg3IMDEMakOChtG1SziJUzq3X3gBaze9%7ECZNcpYgvQYNsS71LGBWvmAclOQNq6fstsVJU9awitADDqmB4IfY7lkUFBPQKp8khXKJboPWUxmMc2OT6vGNAPrXj8UxEdHCfx65MwDSFxdalB2-TV6B45mQxP6YCpOjJMl4IGQfag--o0tWLI%7Euxdmu22dzaMYGrXEqte0WOEKijcE7JvBNneSdYvAaPcpqeRwutlMJ9akw__&Key-Pair-Id=K24J24Z295AEI9 to /tmp/chesapeake/de_lulc_2013_2022-Edition.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 342966050/342966050 [00:03<00:00, 112920466.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://hf.co/datasets/torchgeo/chesapeake/resolve/1e0370eda6a24d93af4153745e54fd383d015bf5/de_lulc_2018_2022-Edition.zip\n",
            "Downloading https://cdn-lfs-us-1.hf.co/repos/b1/d9/b1d907e4abc2017ba5639b5383cb747c467032b813359bb2ceb94fe88674bac3/4b996051cbd532dc4e43642d4ecbdf2dd55456a927edc35983b427f137145273?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27de_lulc_2018_2022-Edition.zip%3B+filename%3D%22de_lulc_2018_2022-Edition.zip%22%3B&response-content-type=application%2Fzip&Expires=1727737214&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzczNzIxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2IxL2Q5L2IxZDkwN2U0YWJjMjAxN2JhNTYzOWI1MzgzY2I3NDdjNDY3MDMyYjgxMzM1OWJiMmNlYjk0ZmU4ODY3NGJhYzMvNGI5OTYwNTFjYmQ1MzJkYzRlNDM2NDJkNGVjYmRmMmRkNTU0NTZhOTI3ZWRjMzU5ODNiNDI3ZjEzNzE0NTI3Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=X7MquGN-BXpoPLZf16wfnpLNYLFi9WZb-MUjGIOyNGU%7Eb36bLYCUMAPY5GhVqKMJQl9YQ2DJkMQseJqI%7EW716N6tybiVBm45ngc6FN5QAP7l5jZ8bhNeV2Gk3I46odZ4W-AcGvF9YtsVjyfqn8kQna5v1PSvouOZkgKBRxeCIyPh0%7ENqOn7iiwl83pQvXngInQnyXjw1UZqjMobyJbc1qn2v%7Ez2JCXev7tJ9946ws0gJjAoSEABIr9-7ClY8nTCmOgIrPtSr4OXnFkH%7E9PvadbcAmdpCwVk6d%7E%7ExVArRvPZ7HFF-36o-Cxj2XcTCcPTpsq2YjXc8E5tH3cq6bCMLag__&Key-Pair-Id=K24J24Z295AEI9 to /tmp/chesapeake/de_lulc_2018_2022-Edition.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 348540992/348540992 [00:02<00:00, 116923861.23it/s]\n"
          ]
        }
      ],
      "source": [
        "chesapeake_root = os.path.join(tempfile.gettempdir(), 'chesapeake')\n",
        "os.makedirs(chesapeake_root, exist_ok=True)\n",
        "chesapeake = ChesapeakeDE(chesapeake_root, crs=naip.crs, res=naip.res, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f2d78b",
      "metadata": {
        "id": "56f2d78b"
      },
      "source": [
        "Finally, we create an IntersectionDataset so that we can automatically sample from both GeoDatasets simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "daefbc4d",
      "metadata": {
        "id": "daefbc4d"
      },
      "outputs": [],
      "source": [
        "dataset = naip & chesapeake"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ded44652",
      "metadata": {
        "id": "ded44652"
      },
      "source": [
        "## Sampler\n",
        "\n",
        "Unlike typical PyTorch Datasets, TorchGeo GeoDatasets are indexed using lat/long/time bounding boxes. This requires us to use a custom GeoSampler instead of the default sampler/batch_sampler that comes with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b8a0d99c",
      "metadata": {
        "id": "b8a0d99c"
      },
      "outputs": [],
      "source": [
        "sampler = RandomGeoSampler(dataset, size=1000, length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8c1c52",
      "metadata": {
        "id": "5b8c1c52"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "Now that we have a Dataset and Sampler, we can combine these into a single DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "96faa142",
      "metadata": {
        "id": "96faa142"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, sampler=sampler, collate_fn=stack_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ae63f7",
      "metadata": {
        "id": "64ae63f7"
      },
      "source": [
        "## Training\n",
        "\n",
        "Other than that, the rest of the training pipeline is the same as it is for torchvision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a2b44f8",
      "metadata": {
        "id": "8a2b44f8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "WarpedVRT does not permit boundless reads",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torchgeo/datasets/geo.py:1027\u001b[0m, in \u001b[0;36mIntersectionDataset.__getitem__\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in index with bounds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# All datasets are guaranteed to have a valid query\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1029\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(samples)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torchgeo/datasets/geo.py:1027\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in index with bounds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# All datasets are guaranteed to have a valid query\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m samples \u001b[38;5;241m=\u001b[39m [\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets]\n\u001b[1;32m   1029\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(samples)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torchgeo/datasets/geo.py:550\u001b[0m, in \u001b[0;36mRasterDataset.__getitem__\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    548\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(data_list)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mband_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m'\u001b[39m: query}\n\u001b[1;32m    554\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/torchgeo/datasets/geo.py:587\u001b[0m, in \u001b[0;36mRasterDataset._merge_files\u001b[0;34m(self, filepaths, query, band_indexes)\u001b[0m\n\u001b[1;32m    584\u001b[0m     vrt_fhs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_warp_file(fp) \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m filepaths]\n\u001b[1;32m    586\u001b[0m bounds \u001b[38;5;241m=\u001b[39m (query\u001b[38;5;241m.\u001b[39mminx, query\u001b[38;5;241m.\u001b[39mminy, query\u001b[38;5;241m.\u001b[39mmaxx, query\u001b[38;5;241m.\u001b[39mmaxy)\n\u001b[0;32m--> 587\u001b[0m dest, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvrt_fhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresampling\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Use array_to_tensor since merge may return uint16/uint32 arrays.\u001b[39;00m\n\u001b[1;32m    591\u001b[0m tensor \u001b[38;5;241m=\u001b[39m array_to_tensor(dest)\n",
            "File \u001b[0;32m~/miniconda3/envs/pyt2/lib/python3.11/site-packages/rasterio/merge.py:431\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(sources, bounds, res, nodata, dtype, precision, indexes, output_count, resampling, method, target_aligned_pixels, mem_limit, use_highest_res, masked, dst_path, dst_kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m     src_window \u001b[38;5;241m=\u001b[39m windows\u001b[38;5;241m.\u001b[39mfrom_bounds(\n\u001b[1;32m    426\u001b[0m         dst_w, dst_s, dst_e, dst_n, src\u001b[38;5;241m.\u001b[39mtransform\n\u001b[1;32m    427\u001b[0m     )\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    429\u001b[0m     temp_shape \u001b[38;5;241m=\u001b[39m (src_count, chunk\u001b[38;5;241m.\u001b[39mheight, chunk\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[0;32m--> 431\u001b[0m     temp_src \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mboundless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmasked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m region \u001b[38;5;241m=\u001b[39m dest[:, :, :]\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cmath\u001b[38;5;241m.\u001b[39misnan(nodataval):\n",
            "File \u001b[0;32mrasterio/_warp.pyx:1326\u001b[0m, in \u001b[0;36mrasterio._warp.WarpedVRTReaderBase.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: WarpedVRT does not permit boundless reads"
          ]
        }
      ],
      "source": [
        "for sample in dataloader:\n",
        "    image = sample['image']\n",
        "    target = sample['mask']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "getting_started.ipynb",
      "provenance": []
    },
    "execution": {
      "timeout": 1200
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
