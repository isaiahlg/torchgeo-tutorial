{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYndcZst_kdr"
      },
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKIkyiLScf9P"
      },
      "source": [
        "# Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PevsPoE4cY0j"
      },
      "source": [
        "In this tutorial, we demonstrate how to use TorchGeo's data augmentation transforms and provide examples of how to utilize them in your experiments with multispectral imagery.\n",
        "\n",
        "It's recommended to run this notebook on Google Colab if you don't have your own GPU. Click the \"Open in Colab\" button above to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsOYw-p2ccka"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqdMMzvacOF8"
      },
      "source": [
        "Install TorchGeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOwsb8KT_uXR"
      },
      "outputs": [],
      "source": [
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2f5_f4X_-vV"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvPMr76K_9uk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "import kornia.augmentation as K\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchgeo.datasets import EuroSAT100\n",
        "from torchgeo.transforms import AugmentationSequential, indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR3BCeV2AAop"
      },
      "source": [
        "## Custom Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVgqhF2udp4z"
      },
      "source": [
        "Here we create a transform to show an example of how you can chain custom operations along with TorchGeo and Kornia transforms/augmentations. Note how our transform takes as input a Dict of Tensors. We specify our data by the keys [\"image\", \"mask\", \"label\", etc.] and follow this standard across TorchGeo datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mixIK7mAC9G"
      },
      "outputs": [],
      "source": [
        "class MinMaxNormalize(K.IntensityAugmentationBase2D):\n",
        "    \"\"\"Normalize channels to the range [0, 1] using min/max values.\"\"\"\n",
        "\n",
        "    def __init__(self, mins: Tensor, maxs: Tensor) -> None:\n",
        "        super().__init__(p=1)\n",
        "        self.flags = {'mins': mins.view(1, -1, 1, 1), 'maxs': maxs.view(1, -1, 1, 1)}\n",
        "\n",
        "    def apply_transform(\n",
        "        self,\n",
        "        input: Tensor,\n",
        "        params: dict[str, Tensor],\n",
        "        flags: dict[str, int],\n",
        "        transform: Tensor | None = None,\n",
        "    ) -> Tensor:\n",
        "        return (input - flags['mins']) / (flags['maxs'] - flags['mins'] + 1e-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ESh5W05AE3Y"
      },
      "source": [
        "## Dataset Bands and Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFTBPWUo9b5o"
      },
      "source": [
        "Below we have min/max values calculated across the dataset per band. The values were clipped to the interval [0, 98] to stretch the band values and avoid outliers influencing the band histograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRnMovSrAHgU"
      },
      "outputs": [],
      "source": [
        "mins = torch.tensor(\n",
        "    [\n",
        "        1013.0,\n",
        "        676.0,\n",
        "        448.0,\n",
        "        247.0,\n",
        "        269.0,\n",
        "        253.0,\n",
        "        243.0,\n",
        "        189.0,\n",
        "        61.0,\n",
        "        4.0,\n",
        "        33.0,\n",
        "        11.0,\n",
        "        186.0,\n",
        "    ]\n",
        ")\n",
        "maxs = torch.tensor(\n",
        "    [\n",
        "        2309.0,\n",
        "        4543.05,\n",
        "        4720.2,\n",
        "        5293.05,\n",
        "        3902.05,\n",
        "        4473.0,\n",
        "        5447.0,\n",
        "        5948.05,\n",
        "        1829.0,\n",
        "        23.0,\n",
        "        4894.05,\n",
        "        4076.05,\n",
        "        5846.0,\n",
        "    ]\n",
        ")\n",
        "bands = {\n",
        "    'B01': 'Coastal Aerosol',\n",
        "    'B02': 'Blue',\n",
        "    'B03': 'Green',\n",
        "    'B04': 'Red',\n",
        "    'B05': 'Vegetation Red Edge 1',\n",
        "    'B06': 'Vegetation Red Edge 2',\n",
        "    'B07': 'Vegetation Red Edge 3',\n",
        "    'B08': 'NIR 1',\n",
        "    'B8A': 'NIR 2',\n",
        "    'B09': 'Water Vapour',\n",
        "    'B10': 'SWIR 1',\n",
        "    'B11': 'SWIR 2',\n",
        "    'B12': 'SWIR 3',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ40TIOG9qVZ"
      },
      "source": [
        "The following variables can be used to control the dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKGubYto9qVZ",
        "nbmake": {
          "mock": {
            "batch_size": 1,
            "num_workers": 0
          }
        }
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "num_workers = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hktYHfQHAJbs"
      },
      "source": [
        "## Load the EuroSat MS dataset and dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUavkZSxeqCA"
      },
      "source": [
        "We will use the [EuroSAT](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#eurosat) dataset throughout this tutorial. Specifically, a subset containing only 100 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHVgiNA4t5Tl"
      },
      "outputs": [],
      "source": [
        "root = os.path.join(tempfile.gettempdir(), 'eurosat100')\n",
        "dataset = EuroSAT100(root, download=True)\n",
        "dataloader = DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "dataloader = iter(dataloader)\n",
        "print(f'Number of images in dataset: {len(dataset)}')\n",
        "print(f'Dataset Classes: {dataset.classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovckKTXpA78o"
      },
      "source": [
        "## Load a sample and batch of images and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKYU2A3weY82"
      },
      "source": [
        "Here we test our dataset by loading a single image and label. Note how the image is of shape (13, 64, 64) containing a 64x64 shape with 13 multispectral bands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lhG1yM_v7Mi"
      },
      "outputs": [],
      "source": [
        "sample = dataset[0]\n",
        "x, y = sample['image'], sample['label']\n",
        "print(x.shape, x.dtype, x.min(), x.max())\n",
        "print(y, dataset.classes[y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw8F17tcAKPY"
      },
      "source": [
        "Here we test our dataloader by loading a single batch of images and labels. Note how the image is of shape (4, 13, 64, 64) containing 4 samples due to our batch_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0faJA5UiAJmK"
      },
      "outputs": [],
      "source": [
        "batch = next(dataloader)\n",
        "x, y = batch['image'], batch['label']\n",
        "print(x.shape, x.dtype, x.min(), x.max())\n",
        "print(y, [dataset.classes[i] for i in y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-uLsPdfz0o"
      },
      "source": [
        "## Transforms Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p28C8cTGE3dP"
      },
      "source": [
        "Transforms are able to operate across batches of samples and singular samples. This allows them to be used inside the dataset itself or externally, chained together with other transform operations using `nn.Sequential`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJXUycffEjNX"
      },
      "outputs": [],
      "source": [
        "transform = MinMaxNormalize(mins, maxs)\n",
        "print(x.shape)\n",
        "x = transform(x)\n",
        "print(x.dtype, x.min(), x.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRjb-u0EEmDf"
      },
      "source": [
        "Indices can also be computed on batches of images and appended as an additional band to the specified channel dimension. Notice how the number of channels increases from 13 -> 14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaG-1tvi9RKS"
      },
      "outputs": [],
      "source": [
        "transform = indices.AppendNDVI(index_nir=7, index_red=3)\n",
        "batch = next(dataloader)\n",
        "x = batch['image']\n",
        "print(x.shape)\n",
        "x = transform(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6WFG8UuGcF8"
      },
      "source": [
        "This makes it incredibly easy to add indices as additional features during training by chaining multiple Appends together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_EaAyfnGblR"
      },
      "outputs": [],
      "source": [
        "transforms = nn.Sequential(\n",
        "    MinMaxNormalize(mins, maxs),\n",
        "    indices.AppendNDBI(index_swir=11, index_nir=7),\n",
        "    indices.AppendNDSI(index_green=3, index_swir=11),\n",
        "    indices.AppendNDVI(index_nir=7, index_red=3),\n",
        "    indices.AppendNDWI(index_green=2, index_nir=7),\n",
        ")\n",
        "\n",
        "batch = next(dataloader)\n",
        "x = batch['image']\n",
        "print(x.shape)\n",
        "x = transforms(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ZbjxPyHoiB"
      },
      "source": [
        "It's even possible to chain indices along with augmentations from Kornia for a single callable during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKEDgnX0Hn-d"
      },
      "outputs": [],
      "source": [
        "transforms = AugmentationSequential(\n",
        "    MinMaxNormalize(mins, maxs),\n",
        "    indices.AppendNDBI(index_swir=11, index_nir=7),\n",
        "    indices.AppendNDSI(index_green=3, index_swir=11),\n",
        "    indices.AppendNDVI(index_nir=7, index_red=3),\n",
        "    indices.AppendNDWI(index_green=2, index_nir=7),\n",
        "    K.RandomHorizontalFlip(p=0.5),\n",
        "    K.RandomVerticalFlip(p=0.5),\n",
        "    data_keys=['image'],\n",
        ")\n",
        "\n",
        "batch = next(dataloader)\n",
        "print(batch['image'].shape)\n",
        "batch = transforms(batch)\n",
        "print(batch['image'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKin8a2GPoI"
      },
      "source": [
        "All of our transforms are `nn.Modules`. This allows us to push them and the data to the GPU to see significant gains for large scale operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QhMOtYzLmVK",
        "tags": [
          "raises-exception"
        ]
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zokGELhGPF8"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transforms = AugmentationSequential(\n",
        "    MinMaxNormalize(mins, maxs),\n",
        "    indices.AppendNDBI(index_swir=11, index_nir=7),\n",
        "    indices.AppendNDSI(index_green=3, index_swir=11),\n",
        "    indices.AppendNDVI(index_nir=7, index_red=3),\n",
        "    indices.AppendNDWI(index_green=2, index_nir=7),\n",
        "    K.RandomHorizontalFlip(p=0.5),\n",
        "    K.RandomVerticalFlip(p=0.5),\n",
        "    K.RandomAffine(degrees=(0, 90), p=0.25),\n",
        "    K.RandomGaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0), p=0.25),\n",
        "    K.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0), p=0.25),\n",
        "    data_keys=['image'],\n",
        ")\n",
        "\n",
        "transforms_gpu = AugmentationSequential(\n",
        "    MinMaxNormalize(mins.to(device), maxs.to(device)),\n",
        "    indices.AppendNDBI(index_swir=11, index_nir=7),\n",
        "    indices.AppendNDSI(index_green=3, index_swir=11),\n",
        "    indices.AppendNDVI(index_nir=7, index_red=3),\n",
        "    indices.AppendNDWI(index_green=2, index_nir=7),\n",
        "    K.RandomHorizontalFlip(p=0.5),\n",
        "    K.RandomVerticalFlip(p=0.5),\n",
        "    K.RandomAffine(degrees=(0, 90), p=0.25),\n",
        "    K.RandomGaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0), p=0.25),\n",
        "    K.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0), p=0.25),\n",
        "    data_keys=['image'],\n",
        ").to(device)\n",
        "\n",
        "\n",
        "def get_batch_cpu():\n",
        "    return dict(image=torch.randn(64, 13, 512, 512).to('cpu'))\n",
        "\n",
        "\n",
        "def get_batch_gpu():\n",
        "    return dict(image=torch.randn(64, 13, 512, 512).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo43CqJ4IIXE"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 1 -r 5\n",
        "_ = transforms(get_batch_cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICKXYZYrJCeh"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 1 -r 5\n",
        "_ = transforms_gpu(get_batch_gpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkGy_g6tBAtF"
      },
      "source": [
        "## Visualize Images and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k4W98v27NtL"
      },
      "source": [
        "This is a Google Colab browser for the EuroSAT dataset. Adjust the slider to visualize images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_6k7tcxz17x"
      },
      "outputs": [],
      "source": [
        "transforms = AugmentationSequential(MinMaxNormalize(mins, maxs), data_keys=['image'])\n",
        "dataset = EuroSAT100(root, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw8xDeg3BY-u"
      },
      "outputs": [],
      "source": [
        "# @title EuroSat Multispectral (MS) Browser  { run: \"auto\", vertical-output: true }\n",
        "idx = 21  # @param {type:\"slider\", min:0, max:59, step:1}\n",
        "sample = dataset[idx]\n",
        "rgb = sample['image'][0, 1:4]\n",
        "image = T.ToPILImage()(rgb)\n",
        "print(f\"Class Label: {dataset.classes[sample['label']]}\")\n",
        "image.resize((256, 256), resample=Image.BILINEAR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "execution": {
      "timeout": 1200
    },
    "interpreter": {
      "hash": "6e850ee5f92358dcfdbb90dda05d686956eb0825584ddd5eff31b34875ddfee0"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}