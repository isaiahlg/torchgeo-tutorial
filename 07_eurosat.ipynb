{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoML with EuroSAT Notebook\n",
    "In this notebook, we download and visualize EuroSAT data from both the spatial and non-spatial splits. We then train two ResNet50 image encoders on each dataset, one with randomly initialized weights and one with pre-initialized weights from SSL4EO-S12. We then evaluate each on the test and train data, and then customize the training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data libraries\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import EuroSAT, EuroSATSpatial, EuroSAT100\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml libraries\n",
    "import torch # for model training\n",
    "from torch import nn # for neural network layers\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms # to resize input images\n",
    "from torchgeo.models import resnet50 # import resnet50 model from torchvision\n",
    "from torchgeo.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Visualize EuroSat Data\n",
    "\n",
    "In this section, we use the torchgeo dataset/datamodules to download the EuroSat dataset (spatial and nonspatial split versions). We then plot a random sample of 6 images (with labels) from the training set and the test set for each dataset version. We also calculate the number of samples in each split for each version (spatial and nonspatial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 60\n",
      "Number of images in test dataset: 20\n"
     ]
    }
   ],
   "source": [
    "eurosat100_root = os.path.join(\"data\", \"eurosat100\")\n",
    "eurosat100_dataset_train = EuroSAT100(eurosat100_root, split=\"train\", download=True)\n",
    "eurosat100_dataset_test = EuroSAT100(eurosat100_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat100_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat100_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat100_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://cdn-lfs.hf.co/repos/fc/1d/fc1dee780dee1dae2ad48856d0961ac6aa5dfcaaaa4fb3561be4aedf19b7ccc7/751f070f9bffa2eed48b24ca2dd0b02959280c08837e8c9a5532a67ba611df59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27EuroSATallBands.zip%3B+filename%3D%22EuroSATallBands.zip%22%3B&response-content-type=application%2Fzip&Expires=1729110697&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTExMDY5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9mYy8xZC9mYzFkZWU3ODBkZWUxZGFlMmFkNDg4NTZkMDk2MWFjNmFhNWRmY2FhYWE0ZmIzNTYxYmU0YWVkZjE5YjdjY2M3Lzc1MWYwNzBmOWJmZmEyZWVkNDhiMjRjYTJkZDBiMDI5NTkyODBjMDg4MzdlOGM5YTU1MzJhNjdiYTYxMWRmNTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=QoH6y1-GyrDfVJE8nhkc9qHr3Jc3QQpXcScCCcelRJTDrZYTNeWLjhZmGrG2%7EV%7EVLZOJMchgllqfTm8tuc2FaBfeC6kJe07pCgOZxTT8AvuZw4nOg8%7Ez5j9k1Joe88G-CqcKGfiY-R6aUhzP1cQmY1gRb8DLU8Nfhl0bSAIBsvBf%7EZKwyeogc2DNB4CrYtkQptZ5Ntma%7EsTrLjZ%7Emc3qyuk%7Ejfgeg6uXIdnqLtnVOTZ%7EfgyqM-hLda3WQN9k78TUzPLtTWY2M2LAtRKqJSK4OYkItzePUpoVCBsN06T24Ri3BJzBJhGt1IRZfeWv3ly4pUfGO6UVePFEFGILELgTiw__&Key-Pair-Id=K3RPWS32NSSJCE to data/eurosat/EuroSATallBands.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2067725275/2067725275 [00:24<00:00, 84878165.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/remote_sensing_representations/eurosat-train.txt to data/eurosat/eurosat-train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313605/313605 [00:00<00:00, 12787691.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/remote_sensing_representations/eurosat-val.txt to data/eurosat/eurosat-val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104659/104659 [00:00<00:00, 4067377.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/remote_sensing_representations/eurosat-test.txt to data/eurosat/eurosat-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104163/104163 [00:00<00:00, 5735739.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 16200\n",
      "Number of images in test dataset: 5400\n"
     ]
    }
   ],
   "source": [
    "eurosat_root = os.path.join(\"data\", \"eurosat\")\n",
    "eurosat_dataset_train = EuroSAT(eurosat_root, split=\"train\", download=True)\n",
    "eurosat_dataset_test = EuroSAT(eurosat_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://cdn-lfs.hf.co/repos/fc/1d/fc1dee780dee1dae2ad48856d0961ac6aa5dfcaaaa4fb3561be4aedf19b7ccc7/751f070f9bffa2eed48b24ca2dd0b02959280c08837e8c9a5532a67ba611df59?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27EuroSATallBands.zip%3B+filename%3D%22EuroSATallBands.zip%22%3B&response-content-type=application%2Fzip&Expires=1729110781&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTExMDc4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9mYy8xZC9mYzFkZWU3ODBkZWUxZGFlMmFkNDg4NTZkMDk2MWFjNmFhNWRmY2FhYWE0ZmIzNTYxYmU0YWVkZjE5YjdjY2M3Lzc1MWYwNzBmOWJmZmEyZWVkNDhiMjRjYTJkZDBiMDI5NTkyODBjMDg4MzdlOGM5YTU1MzJhNjdiYTYxMWRmNTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=DNrMBebkesVH550RdD7iAbmrtSv9ofz7DcSU3B6iqOalKiZTKirJFJNkofrUxO%7EaX76363epqktkZCzCGw29GgjyQUXMm0OwYLvkWxupWKbpijxAoGa8Z60Z4WoyknunRs1v5IphINziXw6IuS%7E4mqW0GUrr1urjC6AT3JjxUimuvD5G55cMV6IjxU5E6CquaNObMRjLBi%7EpnCe6Txaa6W7lgdI6-8HpR%7EmBIhqDzaxAlHAPrEqY855kKQmlTtoF5%7EqMOdR81Q1Itlq%7ED3xkIwNljWa7rJD7jwl%7ENAgZA5SvuHmikhf6D02LpD7bIA-FvxLPEKPS53Z3wGTz41kYwg__&Key-Pair-Id=K3RPWS32NSSJCE to data/eurosatSpatial/EuroSATallBands.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2067725275/2067725275 [00:17<00:00, 115761874.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://huggingface.co/datasets/torchgeo/eurosat/resolve/1c11c73a87b40b0485d103231a97829991b8e22f/eurosat-spatial-train.txt to data/eurosatSpatial/eurosat-train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316710/316710 [00:00<00:00, 2815153.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://huggingface.co/datasets/torchgeo/eurosat/resolve/1c11c73a87b40b0485d103231a97829991b8e22f/eurosat-spatial-val.txt to data/eurosatSpatial/eurosat-val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99786/99786 [00:00<00:00, 26501159.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://huggingface.co/datasets/torchgeo/eurosat/resolve/1c11c73a87b40b0485d103231a97829991b8e22f/eurosat-spatial-test.txt to data/eurosatSpatial/eurosat-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105934/105934 [00:00<00:00, 1216963.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 16200\n",
      "Number of images in test dataset: 5400\n"
     ]
    }
   ],
   "source": [
    "eurosat_spatial_root = os.path.join(\"data\", \"eurosatSpatial\")\n",
    "eurosat_spatial_dataset_train = EuroSATSpatial(eurosat_spatial_root, split=\"train\", download=True)\n",
    "eurosat_spatial_dataset_test = EuroSATSpatial(eurosat_spatial_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat_spatial_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat_spatial_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat_spatial_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # of Images in Each Dataset Split\n",
    "Split    | EuroSAT100   | EuroSAT   | EuroSAT Spatial   |\n",
    "---------|-----------   |---------  |---------          |\n",
    "Train    |  60          |   16200   |   16200           |\n",
    "Validate |  20          |   5400    |   5400            |\n",
    "Test     |  20          |   5400    |   5400            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Images and Labels from Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "random.seed(44)\n",
    "\n",
    "eurosat_datasets = {\n",
    "    \"eurosat_train\": eurosat_dataset_train,\n",
    "    \"eurosat_test\": eurosat_dataset_test,\n",
    "    \"eurosat_spatial_train\": eurosat_spatial_dataset_train,\n",
    "    \"eurosat_spatial_test\": eurosat_spatial_dataset_test\n",
    "}\n",
    "figures_base_path = os.path.join(\"figures\", \"eurosat100\")\n",
    "\n",
    "\n",
    "# sample 6 random images, plot, and export the figures\n",
    "for name, dataset in eurosat_datasets.items():\n",
    "    n = 0\n",
    "    for i in random.sample(range(len(dataset)), 6):\n",
    "        fig = dataset.plot(\n",
    "            sample=dataset.__getitem__(i),\n",
    "            show_titles=True\n",
    "        )\n",
    "        # export fig to png\n",
    "        path = os.path.join(\"figures\", \"eurosat\", f\"{name}_{n}.png\")\n",
    "        fig.savefig(path)\n",
    "        plt.close(fig)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize just one image\n",
    "fig = eurosat_dataset_train.plot(\n",
    "    sample=eurosat_dataset_train.__getitem__(0),\n",
    "    show_titles=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train & Evaluate a Model on the EuroSAT Data \n",
    "\n",
    "In this section, we train two ResNet 50 models on the nonspatial EuroSat dataset: one with randomly initialized weights, and one with pre-initialized weights from the SSL4EO-S12 project (use the pretrained weights available in torchgeo). We report the performance of these models on the train and test sets in a table. In addition to the table, we report (i) how we implemented the training and evaluation procedure, what hyperparameters we use to train the model, and how we choose those hyperparameters (e.g. if we perform a cross-validation search for hyperparameters, we explain how you conducted that search), (ii) what pretrained weights we choose to use, and a short description of the process used to generate those weights, (iii) a short paragraph describing the results in your table in words.\n",
    "\n",
    "The flow of this section is as follows:\n",
    "1. Configure the GPU\n",
    "1. Define the Train and Test Loos\n",
    "1. Define a ResNet model with random weights, customize the model for EuroSat data\n",
    "1. Define a data sampler and loader\n",
    "1. Load and transform the data\n",
    "1. Train & evaluate the model\n",
    "1. Repeat with a pre-trained ResNet50\n",
    "1. Report results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Train & Test Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "# from the pytorch tutorial\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "        X, y = sample['image'], sample['label']\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print intermediate results every n batches\n",
    "        n = 20\n",
    "        if batch % n == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "# from the pytorch tutorial\n",
    "def test(dataloader, model, loss_fn, val=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader:\n",
    "            X, y = sample['image'], sample['label']\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    prefix = \"Validation\" if val else \"Test\"\n",
    "    print(f\"{prefix} Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "model = resnet50(weights=None).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the ResNet model to have 10 output classes\n",
    "model.fc = nn.Linear(2048, 10).to(device)\n",
    "\n",
    "# modify the model to expect 13 channels instead of 3\n",
    "model.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "# define training parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transform function to handle the dictionary structure of torchgeo dataset\n",
    "class CustomTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "    \n",
    "# Define transformations for the dataset to get it from 64x64 to 224x224\n",
    "transform = transforms.Resize((224, 224))  # Resizes the images to 224x224\n",
    "\n",
    "custom_transform = CustomTransform(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# reload data with the new transform\n",
    "root = os.path.join(\"data\", \"eurosat\")\n",
    "dataset_train = EuroSAT(root, split=\"train\", download=True, transforms=custom_transform)\n",
    "dataset_val = EuroSAT(root, split=\"val\", download=True, transforms=custom_transform)\n",
    "dataset_test = EuroSAT(root, split=\"test\", download=True, transforms=custom_transform)\n",
    "\n",
    "# define a sampler for the EuroSAT dataset\n",
    "# it's a non-spatial dataset, so we can use a regular sampler from pytorch\n",
    "sampler_train = RandomSampler(dataset_train, replacement=False) # start with a small batch\n",
    "sampler_val = RandomSampler(dataset_val, replacement=False) # start with a small batch\n",
    "sampler_test = RandomSampler(dataset_test, replacement=False) # start with a small batch\n",
    "\n",
    "# define a dataloader to iterate over the dataset\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_train)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, sampler=sampler_val)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, sampler=sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.790203  [   64/16200]\n",
      "loss: 2.353432  [ 1344/16200]\n",
      "loss: 2.208539  [ 2624/16200]\n",
      "loss: 2.197552  [ 3904/16200]\n",
      "loss: 2.241841  [ 5184/16200]\n",
      "loss: 2.145606  [ 6464/16200]\n",
      "loss: 2.091316  [ 7744/16200]\n",
      "loss: 1.980653  [ 9024/16200]\n",
      "loss: 2.001280  [10304/16200]\n",
      "loss: 1.937289  [11584/16200]\n",
      "loss: 2.020346  [12864/16200]\n",
      "loss: 1.924643  [14144/16200]\n",
      "loss: 1.894397  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 2.449632 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.932123  [   64/16200]\n",
      "loss: 1.943989  [ 1344/16200]\n",
      "loss: 1.792065  [ 2624/16200]\n",
      "loss: 1.857733  [ 3904/16200]\n",
      "loss: 1.807787  [ 5184/16200]\n",
      "loss: 1.723712  [ 6464/16200]\n",
      "loss: 2.006612  [ 7744/16200]\n",
      "loss: 1.615973  [ 9024/16200]\n",
      "loss: 1.617400  [10304/16200]\n",
      "loss: 1.547189  [11584/16200]\n",
      "loss: 1.550488  [12864/16200]\n",
      "loss: 1.702696  [14144/16200]\n",
      "loss: 1.819835  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 1.899144 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.729539  [   64/16200]\n",
      "loss: 1.456284  [ 1344/16200]\n",
      "loss: 1.459427  [ 2624/16200]\n",
      "loss: 1.677813  [ 3904/16200]\n",
      "loss: 1.475251  [ 5184/16200]\n",
      "loss: 1.573771  [ 6464/16200]\n",
      "loss: 1.371365  [ 7744/16200]\n",
      "loss: 1.583033  [ 9024/16200]\n",
      "loss: 1.413583  [10304/16200]\n",
      "loss: 1.406075  [11584/16200]\n",
      "loss: 1.498965  [12864/16200]\n",
      "loss: 1.246761  [14144/16200]\n",
      "loss: 1.380179  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 1.568321 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.475270  [   64/16200]\n",
      "loss: 1.291315  [ 1344/16200]\n",
      "loss: 1.337132  [ 2624/16200]\n",
      "loss: 1.307061  [ 3904/16200]\n",
      "loss: 1.267388  [ 5184/16200]\n",
      "loss: 1.275251  [ 6464/16200]\n",
      "loss: 1.433649  [ 7744/16200]\n",
      "loss: 1.181141  [ 9024/16200]\n",
      "loss: 1.477049  [10304/16200]\n",
      "loss: 1.214676  [11584/16200]\n",
      "loss: 1.197791  [12864/16200]\n",
      "loss: 1.233510  [14144/16200]\n",
      "loss: 0.945346  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.324963 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.044051  [   64/16200]\n",
      "loss: 1.119627  [ 1344/16200]\n",
      "loss: 1.272705  [ 2624/16200]\n",
      "loss: 0.962037  [ 3904/16200]\n",
      "loss: 1.147151  [ 5184/16200]\n",
      "loss: 1.235001  [ 6464/16200]\n",
      "loss: 0.997515  [ 7744/16200]\n",
      "loss: 1.040630  [ 9024/16200]\n",
      "loss: 1.065510  [10304/16200]\n",
      "loss: 1.062552  [11584/16200]\n",
      "loss: 0.892679  [12864/16200]\n",
      "loss: 1.001968  [14144/16200]\n",
      "loss: 1.175631  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 1.670111 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.926768  [   64/16200]\n",
      "loss: 1.189131  [ 1344/16200]\n",
      "loss: 1.120647  [ 2624/16200]\n",
      "loss: 1.191902  [ 3904/16200]\n",
      "loss: 1.308753  [ 5184/16200]\n",
      "loss: 1.275442  [ 6464/16200]\n",
      "loss: 1.004140  [ 7744/16200]\n",
      "loss: 0.828601  [ 9024/16200]\n",
      "loss: 0.976872  [10304/16200]\n",
      "loss: 1.076355  [11584/16200]\n",
      "loss: 0.943807  [12864/16200]\n",
      "loss: 1.025366  [14144/16200]\n",
      "loss: 0.998468  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.293339 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.002892  [   64/16200]\n",
      "loss: 1.240838  [ 1344/16200]\n",
      "loss: 1.056093  [ 2624/16200]\n",
      "loss: 0.723834  [ 3904/16200]\n",
      "loss: 0.907881  [ 5184/16200]\n",
      "loss: 0.829200  [ 6464/16200]\n",
      "loss: 0.913362  [ 7744/16200]\n",
      "loss: 0.847594  [ 9024/16200]\n",
      "loss: 0.828234  [10304/16200]\n",
      "loss: 0.902451  [11584/16200]\n",
      "loss: 0.865385  [12864/16200]\n",
      "loss: 0.894762  [14144/16200]\n",
      "loss: 0.871319  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.263669 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.880470  [   64/16200]\n",
      "loss: 0.995009  [ 1344/16200]\n",
      "loss: 0.701284  [ 2624/16200]\n",
      "loss: 0.934267  [ 3904/16200]\n",
      "loss: 0.864553  [ 5184/16200]\n",
      "loss: 0.841608  [ 6464/16200]\n",
      "loss: 0.696842  [ 7744/16200]\n",
      "loss: 0.965064  [ 9024/16200]\n",
      "loss: 1.085174  [10304/16200]\n",
      "loss: 0.812871  [11584/16200]\n",
      "loss: 0.785027  [12864/16200]\n",
      "loss: 0.784574  [14144/16200]\n",
      "loss: 0.792973  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.879941 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.686823  [   64/16200]\n",
      "loss: 0.714477  [ 1344/16200]\n",
      "loss: 0.833100  [ 2624/16200]\n",
      "loss: 0.642776  [ 3904/16200]\n",
      "loss: 0.837323  [ 5184/16200]\n",
      "loss: 0.999693  [ 6464/16200]\n",
      "loss: 0.709144  [ 7744/16200]\n",
      "loss: 1.029752  [ 9024/16200]\n",
      "loss: 0.760986  [10304/16200]\n",
      "loss: 0.754349  [11584/16200]\n",
      "loss: 0.682204  [12864/16200]\n",
      "loss: 0.789401  [14144/16200]\n",
      "loss: 0.819078  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 2.030802 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.797278  [   64/16200]\n",
      "loss: 0.522442  [ 1344/16200]\n",
      "loss: 0.895652  [ 2624/16200]\n",
      "loss: 0.667419  [ 3904/16200]\n",
      "loss: 0.691312  [ 5184/16200]\n",
      "loss: 0.846521  [ 6464/16200]\n",
      "loss: 0.678564  [ 7744/16200]\n",
      "loss: 0.711818  [ 9024/16200]\n",
      "loss: 0.845260  [10304/16200]\n",
      "loss: 0.662795  [11584/16200]\n",
      "loss: 0.833203  [12864/16200]\n",
      "loss: 0.747974  [14144/16200]\n",
      "loss: 0.847764  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.004781 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# baseline before training\n",
    "print(f\"Baseline Before Training\\n-------------------------------\")\n",
    "test(dataloader_val, model, loss_fn)\n",
    "\n",
    "# run train / test loop\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader_train, model, loss_fn, optimizer)\n",
    "    test(dataloader_val, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do's\n",
    "1. Figure out how to save down the model parameters after training\n",
    "1. Figure out how to implement early stopping based on validation loss\n",
    "1. Consider running the model for 10-50 epochs\n",
    "1. Figure out how to plot train and val loss over time for given model runs\n",
    "1. Experiment with the batch size and learning rate\n",
    "1. Add a dynamic learning rate scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train & Evaluate a Model on the EuroSAT Spatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.SENTINEL2_ALL_MOCO).to(device) # note the model with these weights is 90.1MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the ResNet model to have 10 output classes\n",
    "model.fc = nn.Linear(2048, 10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# reload data with the new transform\n",
    "root = os.path.join(\"data\", \"eurosatSpatial\")\n",
    "dataset_train = EuroSATSpatial(root, split=\"train\", download=True, transforms=custom_transform)\n",
    "dataset_val = EuroSATSpatial(root, split=\"val\", download=True, transforms=custom_transform)\n",
    "dataset_test = EuroSATSpatial(root, split=\"test\", download=True, transforms=custom_transform)\n",
    "\n",
    "# define a sampler for the EuroSATSpatial dataset\n",
    "# it's a non-spatial dataset, so we can use a regular sampler from pytorch\n",
    "sampler_train = RandomSampler(dataset_train, replacement=False) # start with a small batch\n",
    "sampler_val = RandomSampler(dataset_val, replacement=False) # start with a small batch\n",
    "sampler_test = RandomSampler(dataset_test, replacement=False) # start with a small batch\n",
    "\n",
    "# define a dataloader to iterate over the dataset\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_train)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, sampler=sampler_val)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, sampler=sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Before Training\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 2.128347 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.183523  [   64/16200]\n",
      "loss: 2.191706  [ 1344/16200]\n",
      "loss: 2.191686  [ 2624/16200]\n",
      "loss: 2.174101  [ 3904/16200]\n",
      "loss: 2.169603  [ 5184/16200]\n",
      "loss: 2.185689  [ 6464/16200]\n",
      "loss: 2.183465  [ 7744/16200]\n",
      "loss: 2.160785  [ 9024/16200]\n",
      "loss: 2.164845  [10304/16200]\n",
      "loss: 2.154418  [11584/16200]\n",
      "loss: 2.159639  [12864/16200]\n",
      "loss: 2.147842  [14144/16200]\n",
      "loss: 2.167273  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 2.043599 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.145595  [   64/16200]\n",
      "loss: 2.134872  [ 1344/16200]\n",
      "loss: 2.147903  [ 2624/16200]\n",
      "loss: 2.156779  [ 3904/16200]\n",
      "loss: 2.130998  [ 5184/16200]\n",
      "loss: 2.131555  [ 6464/16200]\n",
      "loss: 2.136301  [ 7744/16200]\n",
      "loss: 2.120452  [ 9024/16200]\n",
      "loss: 2.129006  [10304/16200]\n",
      "loss: 2.112543  [11584/16200]\n",
      "loss: 2.096720  [12864/16200]\n",
      "loss: 2.107255  [14144/16200]\n",
      "loss: 2.087829  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 1.945767 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.096428  [   64/16200]\n",
      "loss: 2.083039  [ 1344/16200]\n",
      "loss: 2.098876  [ 2624/16200]\n",
      "loss: 2.073727  [ 3904/16200]\n",
      "loss: 2.085787  [ 5184/16200]\n",
      "loss: 2.104873  [ 6464/16200]\n",
      "loss: 2.083529  [ 7744/16200]\n",
      "loss: 2.065322  [ 9024/16200]\n",
      "loss: 2.072426  [10304/16200]\n",
      "loss: 2.045235  [11584/16200]\n",
      "loss: 2.070313  [12864/16200]\n",
      "loss: 2.043235  [14144/16200]\n",
      "loss: 2.047947  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 1.852428 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.027045  [   64/16200]\n",
      "loss: 2.016790  [ 1344/16200]\n",
      "loss: 2.008087  [ 2624/16200]\n",
      "loss: 1.996764  [ 3904/16200]\n",
      "loss: 1.997812  [ 5184/16200]\n",
      "loss: 2.035049  [ 6464/16200]\n",
      "loss: 1.959717  [ 7744/16200]\n",
      "loss: 1.963882  [ 9024/16200]\n",
      "loss: 2.017802  [10304/16200]\n",
      "loss: 2.009404  [11584/16200]\n",
      "loss: 2.012220  [12864/16200]\n",
      "loss: 1.970946  [14144/16200]\n",
      "loss: 1.960462  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 1.678556 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.949543  [   64/16200]\n",
      "loss: 1.992364  [ 1344/16200]\n",
      "loss: 1.954638  [ 2624/16200]\n",
      "loss: 1.922600  [ 3904/16200]\n",
      "loss: 1.904100  [ 5184/16200]\n",
      "loss: 1.934456  [ 6464/16200]\n",
      "loss: 1.958146  [ 7744/16200]\n",
      "loss: 1.938334  [ 9024/16200]\n",
      "loss: 1.895232  [10304/16200]\n",
      "loss: 1.900023  [11584/16200]\n",
      "loss: 1.866298  [12864/16200]\n",
      "loss: 1.880778  [14144/16200]\n",
      "loss: 1.833237  [15424/16200]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 1.583097 \n",
      "\n",
      "Test Results\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 1.791193 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "# baseline before training\n",
    "print(f\"Baseline Before Training\\n-------------------------------\")\n",
    "test(dataloader_test, model, loss_fn, val=False)\n",
    "test(dataloader_val, model, loss_fn, val=True)\n",
    "\n",
    "# run train / val loop\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader_train, model, loss_fn, optimizer)\n",
    "    test(dataloader_val, model, loss_fn)\n",
    "\n",
    "# test result with test data\n",
    "print(\"Test Results\\n-------------------------------\")\n",
    "test(dataloader_test, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the current model weights\n",
    "experiment_name = \"eurosatspatial_resnet50_pretrained_epochs10.pth\"\n",
    "model_weights_path = os.path.join(\"models\", \"eurosat\", experiment_name)\n",
    "torch.save(model.state_dict(), model_weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
