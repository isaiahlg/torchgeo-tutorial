{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoML with EuroSAT Notebook\n",
    "In this notebook, we download and visualize EuroSAT data from both the spatial and non-spatial splits. We then train two ResNet50 image encoders on each dataset, one with randomly initialized weights and one with pre-initialized weights from SSL4EO-S12. We then evaluate each on the test and train data, and then customize the training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Visualize EuroSat Data\n",
    "\n",
    "In this section, we use the torchgeo dataset/datamodules to download the EuroSat dataset (spatial and nonspatial split versions). We then plot a random sample of 6 images (with labels) from the training set and the test set for each dataset version. We also calculate the number of samples in each split for each version (spatial and nonspatial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import EuroSAT, EuroSATSpatial, EuroSAT100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 60\n",
      "Number of images in test dataset: 20\n"
     ]
    }
   ],
   "source": [
    "eurosat100_root = os.path.join(\"data\", \"eurosat100\")\n",
    "eurosat100_dataset_train = EuroSAT100(eurosat100_root, split=\"train\", download=True)\n",
    "eurosat100_dataset_test = EuroSAT100(eurosat100_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat100_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat100_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat100_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 16200\n",
      "Number of images in test dataset: 5400\n"
     ]
    }
   ],
   "source": [
    "eurosat_root = os.path.join(\"data\", \"eurosat\")\n",
    "eurosat_dataset_train = EuroSAT(eurosat_root, split=\"train\", download=True)\n",
    "eurosat_dataset_test = EuroSAT(eurosat_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroSAT Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Classes: ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
      "Number of images in train dataset: 16200\n",
      "Number of images in test dataset: 5400\n"
     ]
    }
   ],
   "source": [
    "eurosat_spatial_root = os.path.join(\"data\", \"eurosatSpatial\")\n",
    "eurosat_spatial_dataset_train = EuroSATSpatial(eurosat_spatial_root, split=\"train\", download=True)\n",
    "eurosat_spatial_dataset_test = EuroSATSpatial(eurosat_spatial_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat_spatial_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat_spatial_dataset_train)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat_spatial_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # of Images in Each Dataset Split\n",
    "Split    | EuroSAT100   | EuroSAT   | EuroSAT Spatial   |\n",
    "---------|-----------   |---------  |---------          |\n",
    "Train    |  60          |   16200   |   16200           |\n",
    "Validate |  20          |   5400    |   5400            |\n",
    "Test     |  20          |   5400    |   5400            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Images and Labels from Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# set seed for reproducibility\n",
    "random.seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat_datasets = {\n",
    "    \"eurosat_train\": eurosat_dataset_train,\n",
    "    \"eurosat_test\": eurosat_dataset_test,\n",
    "    \"eurosat_spatial_train\": eurosat_spatial_dataset_train,\n",
    "    \"eurosat_spatial_test\": eurosat_spatial_dataset_test\n",
    "}\n",
    "figures_base_path = os.path.join(\"figures\", \"eurosat100\")\n",
    "\n",
    "\n",
    "# sample 6 random images, plot, and export the figures\n",
    "for name, dataset in eurosat_datasets.items():\n",
    "    n = 0\n",
    "    for i in random.sample(range(len(dataset)), 6):\n",
    "        fig = dataset.plot(\n",
    "            sample=dataset.__getitem__(i),\n",
    "            show_titles=True\n",
    "        )\n",
    "        # export fig to png\n",
    "        path = os.path.join(\"figures\", \"eurosat\", f\"{name}_{n}.png\")\n",
    "        fig.savefig(path)\n",
    "        plt.close(fig)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize just one image\n",
    "fig = eurosat_dataset_train.plot(\n",
    "    sample=eurosat_dataset_train.__getitem__(0),\n",
    "    show_titles=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train & Evaluate a Model on the EuroSAT Data \n",
    "\n",
    "In this section, we train two ResNet 50 models on the nonspatial EuroSat dataset: one with randomly initialized weights, and one with pre-initialized weights from the SSL4EO-S12 project (use the pretrained weights available in torchgeo). We report the performance of these models on the train and test sets in a table. In addition to the table, we report (i) how we implemented the training and evaluation procedure, what hyperparameters we use to train the model, and how we choose those hyperparameters (e.g. if we perform a cross-validation search for hyperparameters, we explain how you conducted that search), (ii) what pretrained weights we choose to use, and a short description of the process used to generate those weights, (iii) a short paragraph describing the results in your table in words.\n",
    "\n",
    "The flow of this section is as follows:\n",
    "1. Import an empty ResNet50 model\n",
    "1. Define a data sampler and loader\n",
    "1. Train the model\n",
    "1. Evaluate the model\n",
    "1. Conduct a hyperparameter search with cross validation\n",
    "1. Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # for model training\n",
    "from torch import nn # for neural network layers\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms # to resize input images\n",
    "from torchvision.models import resnet50 # import resnet50 model from torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import torchvision\n",
    "model = resnet50().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "# from the pytorch tutorial\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "        X, y = sample['image'], sample['label']\n",
    "        # Ensure the data is in the correct format\n",
    "        if isinstance(X, torch.Tensor) and X.ndim == 4:\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        else:\n",
    "            print(f\"Unexpected data format: {type(X)}, shape: {X.shape if isinstance(X, torch.Tensor) else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "# from the pytorch tutorial\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader:\n",
    "            X, y = sample['image'], sample['label']\n",
    "            # Ensure the data is in the correct format\n",
    "            if isinstance(X, torch.Tensor) and X.ndim == 4:\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            else:\n",
    "                print(f\"Unexpected data format: {type(X)}, shape: {X.shape if isinstance(X, torch.Tensor) else 'N/A'}\")\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Custom transform function to handle the dictionary structure of torchgeo dataset\n",
    "class CustomTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "    \n",
    "# Define transformations for the dataset to get it from 64x64 to 224x224\n",
    "transform = transforms.Resize((224, 224))  # Resizes the images to 224x224\n",
    "\n",
    "custom_transform = CustomTransform(transform)\n",
    "\n",
    "# reload data with the new transform\n",
    "eurosat_root = os.path.join(\"data\", \"eurosat\")\n",
    "eurosat_dataset_train = EuroSAT(eurosat_root, split=\"train\", download=True, transforms=custom_transform)\n",
    "eurosat_dataset_test = EuroSAT(eurosat_root, split=\"test\", download=True, transforms=custom_transform)\n",
    "\n",
    "# define a sampler for the EuroSAT dataset\n",
    "# it's a non-spatial dataset, so we can use a regular sampler from pytorch\n",
    "sampler_train = RandomSampler(eurosat_dataset_train, replacement=False) # start with a small batch\n",
    "dataloader_train = DataLoader(eurosat_dataset_train, batch_size=batch_size, sampler=sampler_train)\n",
    "\n",
    "sampler_test = RandomSampler(eurosat_dataset_test, replacement=False) # start with a small batch\n",
    "dataloader_test = DataLoader(eurosat_dataset_test, batch_size=batch_size, sampler=sampler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the ResNet model to have 10 output classes\n",
    "model.fc = nn.Linear(2048, 10).to(device)\n",
    "\n",
    "# modify the model to expect 13 channels instead of 3\n",
    "model.conv1 = nn.Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train / test loop\n",
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader_train, model, loss_fn, optimizer)\n",
    "    test(dataloader_test, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train & Evaluate a Model on the EuroSAT Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Customize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
